{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vimC0EkkWQZF"
      },
      "outputs": [],
      "source": [
        "# Load various imports\n",
        "#latest version with pitch audio too\n",
        "from datetime import datetime\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Flatten, LSTM, TimeDistributed\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SZfnU9tWQZL",
        "outputId": "62775e58-b0c9-48dd-fb63-f55b0914a517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhusAyAQWQZM"
      },
      "outputs": [],
      "source": [
        "mypath = \"/content/drive/MyDrive/archive/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/\"\n",
        "filenames = [file for file in listdir(mypath) if (isfile(join(mypath, file)) and file.endswith('.wav'))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d0G-AA6WQZN"
      },
      "outputs": [],
      "source": [
        "p_id_in_file = [] # patient IDs corresponding to each file\n",
        "for name in filenames:\n",
        "    p_id_in_file.append(int(name[:3]))\n",
        "\n",
        "p_id_in_file = np.array(p_id_in_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlrT6hJMWQZO"
      },
      "outputs": [],
      "source": [
        "# Adding white noise\n",
        "def add_noise(data):\n",
        "    wn = np.random.randn(len(data))\n",
        "    data_wn = data + 0.002*wn\n",
        "    return data_wn\n",
        "\n",
        "# Shifting the sound\n",
        "def shift_sound(data):\n",
        "    data_shift = np.roll(data, 1600)\n",
        "    return data_shift\n",
        "\n",
        "#streching\n",
        "def stretch(data, rate=0.98):\n",
        "    data = librosa.effects.time_stretch(data, rate)\n",
        "    return data\n",
        "\n",
        "#adding pitch\n",
        "def pitch(data,sr):\n",
        "    return librosa.effects.pitch_shift(data, sr, n_steps=2)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4je0OQ5wWQZP"
      },
      "outputs": [],
      "source": [
        "max_pad_len = 862 # to make the length of all MFCC equal\n",
        "\n",
        "def extract_features(file_name,label):\n",
        "    \"\"\"\n",
        "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
        "    of the audio\"\"\"\n",
        "\n",
        "    try:\n",
        "        mfccs_all = []\n",
        "        allAudio=None\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=20)\n",
        "        if not label == 'COPD':\n",
        "            noise_audio = add_noise(audio)\n",
        "            shift_audio = shift_sound(audio)\n",
        "            stretch_audio = stretch(audio)\n",
        "            pitch_audio = pitch(audio,sample_rate)\n",
        "            allAudio = [audio,noise_audio,shift_audio,stretch_audio,pitch_audio]\n",
        "        else:\n",
        "            allAudio = [audio]\n",
        "\n",
        "        for single_audio in allAudio:\n",
        "            mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "            pad_width = max_pad_len - mfccs.shape[1]\n",
        "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "            mfccs_all.append(mfccs)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file_name)\n",
        "        return None\n",
        "\n",
        "    return mfccs_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-OQNESHWQZR"
      },
      "outputs": [],
      "source": [
        "filepaths = [join(mypath, f) for f in filenames] # full paths of files'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3fWgJ_OWQZS"
      },
      "outputs": [],
      "source": [
        "p_diag = pd.read_csv(\"/content/drive/MyDrive/archive/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv\",header=None) # patient diagnosis file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmhzxVfCWQZS"
      },
      "outputs": [],
      "source": [
        "labels = np.array([p_diag[p_diag[0] == x][1].values[0] for x in p_id_in_file]) # labels for audio files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7kl_jVKWQZU",
        "outputId": "c471990a-0f55-49a7-932b-99bb79ce1df5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['COPD' 'COPD' 'COPD']\n",
            "['/content/drive/MyDrive/archive/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/160_1b2_Tc_mc_AKGC417L.wav', '/content/drive/MyDrive/archive/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/160_1b3_Al_mc_AKGC417L.wav', '/content/drive/MyDrive/archive/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/160_1b2_Pr_mc_AKGC417L.wav']\n"
          ]
        }
      ],
      "source": [
        "print(labels[len(labels)-3:len(labels)])\n",
        "print(filepaths[len(labels)-3:len(labels)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibPKVJ8YWQZV"
      },
      "outputs": [],
      "source": [
        "# print(labels[0:4])\n",
        "# sometest = []\n",
        "# sometest.extend([labels[0],labels[0],labels[0],labels[0]])\n",
        "# print(sometest)\n",
        "# sometest = np.array(sometest)\n",
        "# print(sometest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMRbn5pRWQZW"
      },
      "outputs": [],
      "source": [
        "testPath = \"/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/111_1b3_Tc_sc_Meditron.wav\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "QTx9ISfZWQZY",
        "outputId": "4d81e169-be10-4594-adb8-d3514d8ce337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error encountered while parsing file:  /content/drive/MyDrive/archive/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/160_1b3_Pl_mc_AKGC417L.wav\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ba843c1bd408>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'COPD'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnewLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COPD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ],
      "source": [
        "features = []\n",
        "newLabels = []\n",
        "\n",
        "i = 0\n",
        "# Iterate through each sound file and extract the features\n",
        "for file_name in filepaths:\n",
        "    data = extract_features(file_name,labels[i])\n",
        "    features.extend(data)\n",
        "    if labels[i] == 'COPD':\n",
        "        newLabels.append('COPD')\n",
        "    else:\n",
        "        label = labels[i]\n",
        "        newLabels.extend([label,label,label,label,label])\n",
        "    i+=1\n",
        "\n",
        "print('Finished feature extraction from ', len(features), ' files')\n",
        "print('Finished feature extraction from ', len(newLabels), ' labels')\n",
        "\n",
        "features = np.array(features)\n",
        "labels = np.array(newLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfk_c4beWQZY"
      },
      "outputs": [],
      "source": [
        "# plot an MFCC\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(features[7], x_axis='time')\n",
        "plt.colorbar()\n",
        "plt.title('MFCC')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SHuXhYPWQZZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M7tv0u6WQZZ"
      },
      "outputs": [],
      "source": [
        "# delete the very rare diseases\n",
        "features1 = np.delete(features, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0)\n",
        "\n",
        "labels1 = np.delete(labels, np.where((labels == 'Asthma') | (labels == 'LRTI'))[0], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhYxxTjiWQZa"
      },
      "outputs": [],
      "source": [
        "# print class counts\n",
        "unique_elements, counts_elements = np.unique(labels1, return_counts=True)\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_83BDyQDWQZb"
      },
      "outputs": [],
      "source": [
        "# plot class counts\n",
        "y_pos = np.arange(len(unique_elements))\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, unique_elements)\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Disease')\n",
        "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvGMuw5SWQZc"
      },
      "outputs": [],
      "source": [
        "# One-hot encode labels\n",
        "le = LabelEncoder()\n",
        "i_labels = le.fit_transform(labels1)\n",
        "oh_labels = to_categorical(i_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47UpOY-wWQZc"
      },
      "outputs": [],
      "source": [
        "# add channel dimension for CNN\n",
        "features1 = np.reshape(features1, (*features1.shape,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8NvHr0fWQZd"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(features1, oh_labels, stratify=oh_labels,\n",
        "                                                    test_size=0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt48F5-BWQZd"
      },
      "outputs": [],
      "source": [
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SSlOrM9WQZe"
      },
      "source": [
        "**Convolutional Neural Network (CNN) model architecture**\n",
        "\n",
        "Our model will be a Convolutional Neural Network (CNN) using Keras and a Tensorflow backend.\n",
        "\n",
        "We will use a sequential model, with a simple model architecture, consisting of four Conv2D convolution layers, with our final output layer being a dense layer.\n",
        "\n",
        "The convolution layers are designed for feature detection. It works by sliding a filter window over the input and performing a matrix multiplication and storing the result in a feature map. This operation is known as a convolution.\n",
        "\n",
        "The filter parameter specifies the number of nodes in each layer. Each layer will increase in size from 16, 32, 64 to 128, while the kernel_size parameter specifies the size of the kernel window which in this case is 2 resulting in a 2x2 filter matrix.\n",
        "\n",
        "The first layer will receive the input shape of (40, 862, 1) where 40 is the number of MFCC's, 862 is the number of frames taking padding into account and the 1 signifying that the audio is mono.\n",
        "\n",
        "The activation function we will be using for our convolutional layers is ReLU. We will use a small Dropout value of 20% on our convolutional layers.\n",
        "\n",
        "Each convolutional layer has an associated pooling layer of MaxPooling2D type with the final convolutional layer having a GlobalAveragePooling2D type. The pooling layer is to reduce the dimensionality of the model (by reducing the parameters and subsquent computation requirements) which serves to shorten the training time and reduce overfitting. The Max Pooling type takes the maximum size for each window and the Global Average Pooling type takes the average which is suitable for feeding into our dense output layer.\n",
        "\n",
        "Our output layer will have 6 nodes (num_labels) which matches the number of possible classifications. The activation is for our output layer is softmax. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGaCIi3cWQZg"
      },
      "outputs": [],
      "source": [
        "num_rows = 40\n",
        "num_columns = 862\n",
        "num_channels = 1\n",
        "\n",
        "num_labels = oh_labels.shape[1]\n",
        "filter_size = 3\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=5, strides=1, padding='same', input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHlo-ptqY4df"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paNfXTxUWQZi"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tciN6UCWQZj"
      },
      "outputs": [],
      "source": [
        "# Display model architecture summary\n",
        "model.summary()\n",
        "\n",
        "# Calculate pre-training accuracy\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQBi-oxkWQZj"
      },
      "source": [
        "**Training**\n",
        "\n",
        "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6wMso6lWQZk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvPslJ0ZY-rh"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "num_epochs = 30\n",
        "num_batch_size = 32\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath='mymodel2_{epoch:02d}.h5',\n",
        "        # Path where to save the model\n",
        "        # The two parameters below mean that we will overwrite\n",
        "        # the current checkpoint if and only if\n",
        "        # the `val_accuracy` score has improved.\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        verbose=1)\n",
        "]\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test), callbacks=callbacks, verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKtH-6zYWQZl"
      },
      "source": [
        "**Test the model**\n",
        "\n",
        "Here we will review the accuracy of the model on both the training and test data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvKyWG7IWQZl"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1Q14U_SWQZm"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(x_test) # label scores\n",
        "\n",
        "classpreds = np.argmax(preds, axis=1) # predicted classes\n",
        "\n",
        "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
        "\n",
        "n_classes=6 # number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T05rwhYhWQZm"
      },
      "outputs": [],
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBnzA8aAWQZn"
      },
      "outputs": [],
      "source": [
        "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfXQmEPjWQZn"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curves\n",
        "fig, ax = plt.subplots(figsize=(16, 10))\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('ROC Curve for Each Class')\n",
        "for i in range(n_classes):\n",
        "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
        "ax.legend(loc=\"best\", fontsize='x-large')\n",
        "ax.grid(alpha=.4)\n",
        "sns.despine()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr0ks6MFWQZo"
      },
      "outputs": [],
      "source": [
        "# Classification Report\n",
        "print(classification_report(y_testclass, classpreds, target_names=c_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jwsw7bRWWQZp"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cf_matrix = confusion_matrix(y_testclass, classpreds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpmUl8KhWQZp"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cf_matrix, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1X2ac-BkLQn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "num_rows = 40\n",
        "num_columns = 862\n",
        "num_channels = 1\n",
        "num_labels = oh_labels.shape[1]\n",
        "\n",
        "\n",
        "lstm_model = Sequential()\n",
        "\n",
        "lstm_model.add(LSTM(128, return_sequences=True, input_shape=(num_rows, num_columns,num_channels)))\n",
        "lstm_model.add(Dropout(0.3))\n",
        "lstm_model.add(LSTM(128, return_sequences=True))\n",
        "lstm_model.add(Dropout(0.3))\n",
        "lstm_model.add(TimeDistributed(Dense(256, activation='relu')))\n",
        "lstm_model.add(TimeDistributed(Dense(512, activation='relu')))\n",
        "lstm_model.add(Flatten())\n",
        "lstm_model.add(Dense(units=6, activation='softmax'))\n",
        "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GgObzl9kUEL"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "#train_dir =\n",
        "num_epochs = 30\n",
        "num_batch_size = 64\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath='mymodel3_{epoch:02d}.h5',\n",
        "        # Path where to save the model\n",
        "        # The two parameters below mean that we will overwrite\n",
        "        # the current checkpoint if and only if\n",
        "        # the `val_accuracy` score has improved.\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        verbose=1)\n",
        "]\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
        "          validation_data=(x_test, y_test), callbacks=callbacks, verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTTwpqVUnZXm"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}